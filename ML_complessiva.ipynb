{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a5d8681",
   "metadata": {},
   "source": [
    "# **Machine Learning Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9be223",
   "metadata": {},
   "source": [
    "In questa esercitazione metteremo assieme tutte le nozioni apprese dall'inizio del corso per risolvere un task specifico di machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9126f8",
   "metadata": {},
   "source": [
    "### **Task: Semi-supervised classification**\n",
    "\n",
    "Il task che vogliamo risolvere è un task di classificazione, caratterizzato però dal fatto che solo una piccola parte dei dati che disponiamo possiede le annotazioni (label). Questa condizione è nota come `Semi-supervised learning`. \n",
    "\n",
    "### **Dataset**\n",
    "\n",
    "Il dataset che utilizzeremo sarà Fashion-MNIST, che contiene immagini di articoli di Zalando, composto da un training set di 60.000 campioni e test set con 10.000 campioni. Ogni campione è in scala di grigi e ha risoluzione 28x28. Il dataset è composto da 10 classi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b2838",
   "metadata": {},
   "source": [
    "## **Pseudo-label**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4726ca22",
   "metadata": {},
   "source": [
    "Lo **pseudo-labeling** è una tecnica utilizzata nell'ambito del *semi-supervised learning*. L'idea di base è quella di generare etichette \"artificiali\" (pseudo-etichette) per i dati non etichettati (unlabeled, \"U\"), in modo da utilizzarle durante il training del modello. Per generare queste etichette ci sono diverse strategie: nel contesto di questa esercitazione utilizzeremo un algoritmo di clustering (k-means).\n",
    "\n",
    "Ecco i passaggi generali del processo di pseudo-labeling:\n",
    "\n",
    "1.  **Addestramento Iniziale**: Si addestra un algortimo di clustering sul set non etichettato (U) utilizzando un numero di cluster pari al numero di classi.\n",
    "2.  **Predizione su Dati Etichettati**: Utilizziamo l'algortimo addestrato al punto 1 per clusterizzare i dati etichettati (L), assegnandoli quindi ai cluster che abbiamo trovato durante l' addestramento iniziale.\n",
    "3.  **Mappare i cluster alle etichette**: Creiamo un mapping tra i cluster e le etichette, in modo da capire quale etichetta corrisponde allo specifico cluster. Per fare ciò assegniamo ad ogni cluster la vera label più frequente assegnata a quel cluster, sfruttando la funzione `mode`:\n",
    "\n",
    "```Python\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "etichette_nel_cluster = np.array([0, 1, 1, 2, 1, 0, 1])\n",
    "\n",
    "risultato_mode = mode(etichette_nel_cluster)\n",
    "\n",
    "print(f\"Oggetto ModeResult: {risultato_mode}\") # Output: ModeResul(mode=1, count=4)\n",
    "print(f\"Etichetta più frequente (moda): {risultato_mode.mode}\") # Output: (moda): 1\n",
    "\n",
    "# etichetta più frequente come singolo numero:\n",
    "etichetta_predominante = risultato_mode.mode\n",
    "print(f\"Etichetta predominante per questo cluster: {etichetta_predominante}\") # Output: 1\n",
    "```\n",
    "\n",
    "4.  **Estrazione pseudo-label**: Alla fine, la classe più presente in un cluster diventa l' etichetta scelta per tutti i campioni assegnati a quel cluster. \n",
    "\n",
    "\n",
    "**Vantaggi**:\n",
    "*   Permette di sfruttare la grande quantità di dati non etichettati, che altrimenti andrebbero sprecati.\n",
    "*   Può migliorare significativamente le prestazioni del modello rispetto all'addestramento con i soli dati etichettati, specialmente quando questi ultimi sono scarsi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.stats import mode # For majority voting\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671e368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomi delle classi per Fashion-MNIST\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b5d18",
   "metadata": {},
   "source": [
    "### `load_and_preprocess_data()`\n",
    "\n",
    "In questa funzione dovrete:\n",
    "\n",
    "* Scaricare il dataset.\n",
    "* Riordinare casualmente i dati.\n",
    "* Effettuare reshape.\n",
    "* Scalare i valori dei pixel all' intervallo [0,1].\n",
    "* Ridurre il numero di campioni a 10.000 per il train e 1.000 per il test.\n",
    "\n",
    "La funzione dovrà ritornare nel seguente ordine:\n",
    "\n",
    "1. Il training set ridotto.\n",
    "2. Le etichette di train ridotte.\n",
    "3. Il test set ridotto.\n",
    "4. Le etichette di test ridotte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"Carica e pre-processa il dataset Fashion-MNIST.\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "    #creao gli indici per lo shuffle\n",
    "    indices = np.arange(x_train.shape[0])\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    x_train = x_train[indices]\n",
    "    y_train = y_train[indices]\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1).astype('float32') / 255.0\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1).astype('float32') / 255.0\n",
    "\n",
    "    x_train = x_train[:10000] \n",
    "    y_train = y_train[:10000]\n",
    "\n",
    "    x_test = x_test[:1000]\n",
    "    y_test = y_test[:1000]\n",
    "\n",
    "    print(f\"Shape of training data: {x_train.shape}, Labels: {y_train.shape}\")\n",
    "    print(f\"Shape of test data: {x_test.shape}, Labels: {y_test.shape}\")\n",
    "\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f4f2c",
   "metadata": {},
   "source": [
    "### `apply_pca_and_scale`\n",
    "\n",
    "In questa funzione dovrete:\n",
    "\n",
    "* Scalare il training set e il test set.\n",
    "* Applicare PCA con un numero di componenti specificato come parametro della funzione (o, equivalentemente, con una frazione desiderata della varianza espressa).\n",
    "* Stampare il numero di componenti.\n",
    "* Stampare la varianza espressa.\n",
    "\n",
    "La funzione dovrà ritornare nel seguente ordine:\n",
    "\n",
    "1. Il training set trasformato con PCA.\n",
    "2. Il test set trasformato con PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf661359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca_and_scale(x_train, x_test, n_components):\n",
    "    \"\"\"Applica StandardScaler e PCA.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    x_train_pca = pca.fit_transform(x_train_scaled)\n",
    "    x_test_pca = pca.transform(x_test_scaled)\n",
    "    print(f\"Shape PCA: {x_train_pca.shape}, {x_test_pca.shape}\")\n",
    "    print(f\"Comoìponenti: {pca.n_components_}\")\n",
    "    print(f\"Varianza: {pca.explained_variance_ratio_}\")\n",
    "    \n",
    "    return x_train_pca, x_test_pca, scaler, pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d6064",
   "metadata": {},
   "source": [
    "### `create_semi_supervised_split`\n",
    "\n",
    "In questa funzione dovrete:\n",
    "\n",
    "* Splittare il training set in due insiemi, etichettato (L) e non etichettato (U) utilizzando  `train_test_split` con:\n",
    "\n",
    "`test_size`=`(1.0 - labeled_fraction)`\n",
    "\n",
    "* Stampare la shape del set etichettato.\n",
    "* Stampare la shape del set non etichettato.\n",
    "\n",
    "La funzione deve ritornare nell seguente ordine:\n",
    "\n",
    "1. Il set etichettato.\n",
    "2. Le etichette del set etichettato.\n",
    "3. Il set non etichettato.\n",
    "4. Le etichette del set non etichettato. **N.B.** Queste etichette verranno utilizzate **SOLO** per valutare le pseudo-labels, non per l'addestramento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c868c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_semi_supervised_split(x_train_pca, y_train, labeled_fraction):\n",
    "    \"\"\"Crea gli insiemi etichettato (L) e non etichettato (U).\"\"\"\n",
    "    x_label, x_unlabel, y_label, y_unlabel = train_test_split(\n",
    "        x_train_pca, y_train,\n",
    "        test_size=(1.0 - labeled_fraction),\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"Shape labeled data: {x_label.shape}, Labels: {y_label.shape}\")\n",
    "    print(f\"Shape unlabeled data: {x_unlabel.shape}, Labels: {y_unlabel.shape}\")\n",
    "    \n",
    "    return x_label, y_label, x_unlabel, y_unlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052846d",
   "metadata": {},
   "source": [
    "### `get_pseudo_labels`\n",
    "\n",
    "In questa funzione dovrete:\n",
    "\n",
    "* Istanziare un algoritmo di clustering (ad esempio, k-means).\n",
    "* Addestrare e predire i clustering sul set non etichettato.\n",
    "* Predire i clustering del set etichettato.\n",
    "* Mappare i cluster ad un etichetta, utilizzando per ogni cluster l'etichetta più presente, estraibile utilizzando la funzione `mode` presentata sopra.\n",
    "* Generare un array `pseudo_labels` assegnando a ogni campione del set non etichettato l'etichetta corrispondente al cluster a cui è stato assegnato.\n",
    "\n",
    "La funzione deve ritornare:\n",
    "\n",
    "1. L' array `pseudo_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6560820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudo_labels(x_unlabeled_pca, x_labeled_pca, y_labeled, n_clusters):\n",
    "    \"\"\"Genera pseudo-labels per i dati non etichettati.\"\"\"\n",
    "    \n",
    "    # 1. Istanziare algoritmo di clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    \n",
    "    # 2. Allenare il modello di clustering con i dati non etichettati e salvare le assegnazioni ai cluster\n",
    "    cluster_assignments_unlabeled = kmeans.fit_predict(x_unlabeled_pca)\n",
    "    \n",
    "    # 3. Calcolare l'assegnamento dei dati etichettati ai cluster\n",
    "    cluster_assignments_labeled = kmeans.predict(x_labeled_pca)\n",
    "    \n",
    "    # 4. Mappiamo i cluster alle label vere più frequenti\n",
    "    cluster_to_true_label_map = {}\n",
    "    for k_idx in range(n_clusters):\n",
    "        # 4.1 Troviamo per ogni cluster le etichette vere dei campioni che vi appartengono.\n",
    "        labels_in_cluster = y_labeled[cluster_assignments_labeled == k_idx]\n",
    "        \n",
    "        # 4.2 Troviamo l'etichetta più frequente per quel cluster.\n",
    "        if len(labels_in_cluster) > 0:\n",
    "            most_frequent_label = mode(labels_in_cluster).mode[0]\n",
    "        else:\n",
    "            most_frequent_label = np.nan  # Se il cluster non ha dati etichettati\n",
    "        \n",
    "        # 4.3 Salviamo l'etichetta più frequente per quel cluster in cluster_to_true_label_map.\n",
    "        cluster_to_true_label_map[k_idx] = most_frequent_label\n",
    "    \n",
    "    pseudo_labels_list = []\n",
    "    \n",
    "    for c_assign in cluster_assignments_unlabeled:\n",
    "        if c_assign in cluster_to_true_label_map:\n",
    "            # Assegniamo l'etichetta corrispondente al cluster\n",
    "            pseudo_labels_list.append(cluster_to_true_label_map[c_assign])\n",
    "        else:\n",
    "            # Se il cluster non ha una mappatura, assegniamo NaN\n",
    "            pseudo_labels_list.append(np.nan)\n",
    "    \n",
    "    # 5. Convertiamo la lista in un array numpy\n",
    "    pseudo_labels = np.array(pseudo_labels_list)\n",
    "    \n",
    "    return pseudo_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316409a5",
   "metadata": {},
   "source": [
    "### `train_and_evaluate_classifier`\n",
    "\n",
    "In questa funzione dovrete:\n",
    "\n",
    "* Rimuovere eventuali campioni con etichette NaN (potrebbero provenire da pseudo labels non mappate).\n",
    "* Istanziare il modello utilizzando `model_class` come oggetto e `classifier_args` come argomenti. Esempio:\n",
    "\n",
    "```Python\n",
    "model_class = MLPClassifier\n",
    "classifier_args = {'max_iter': 200, 'hidden_layer_sizes': (100, 50)}\n",
    "model = model_class(**classifier_args)\n",
    "\n",
    "# Equivalente a:\n",
    "model = MLPClassifier(max_iter=200, hidden_layer_sizes=(100, 50))\n",
    "\n",
    "```\n",
    "\n",
    "* Allenare il modello sul training set a cui sono stati rimossi i campioni con etichette NaN.\n",
    "* Calcolare l' accuracy.\n",
    "* Stampare il `title`, che consiste nel titolo dell' esperimento eseguito. Questo perchè tale funzione verrà riutilizzata diverse volte per più set di dati. Un titolo ci permetterà di identificare quali risultati stiamo producendo.\n",
    "* Stampare l' accuracy.\n",
    "* Stampare il classification report.\n",
    "\n",
    "La funzione deve ritornare:\n",
    "\n",
    "1. Il modello.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_classifier(model_class, classifier_args, x_train, y_train, x_test, y_test, title, class_names_list):\n",
    "    # Rimuovere campioni con etichette NaN\n",
    "    valid_indices_train = ~np.isnan(y_train)\n",
    "    x_train_valid = x_train[valid_indices_train]\n",
    "    y_train_valid = y_train[valid_indices_train]\n",
    "\n",
    "    # Istanziare il modello\n",
    "    model = model_class(**classifier_args)\n",
    "\n",
    "    # Allenare il modello\n",
    "    model.fit(x_train_valid, y_train_valid)\n",
    "\n",
    "    # Predire sul test set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calcolare l'accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Stampare i risultati\n",
    "    print(f\"=== {title} ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names_list))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1c37dd",
   "metadata": {},
   "source": [
    "### `main`\n",
    "\n",
    "In questa funzione dovrete:\n",
    "\n",
    "* Utilizzare la funzione `load_and_preprocess_data` per caricare e pre-processare i dati.\n",
    "* Utilizzare la funzione `apply_pca_and_scale` per applicare scaling e PCA.\n",
    "* Utilizzare la funzione `create_semi_supervised_split` per dividere il train set in set etichettato e non etichettato.\n",
    "* Utilizzare la funzione `get_pseudo_labels` per calcoalre le pseudo labels sul set non etichettato.\n",
    "* Calcolare l' accuracy delle pseudo labels, cioè confrontarle con quelle vere in modo da vedere quanto sono accurate.\n",
    "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati etichettati (L).\n",
    "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello solo sui dati non etichettati (U).\n",
    "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello sui dati etichettati (L) più quelli non etichettati (U).\n",
    "* Utilizzare la funzione `train_and_evaluate_classifier` per allenare e valutare il modello su tutto il dataset originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(classifier_class, classifier_args, n_components_pca, labeled_fraction, n_clusters):\n",
    "    # 1. Caricare e pre-processare i dati\n",
    "    x_train, y_train, x_test, y_test = load_and_preprocess_data()\n",
    "\n",
    "    # 2. Applicare scaling e PCA\n",
    "    x_train_pca, x_test_pca, scaler, pca = apply_pca_and_scale(x_train, x_test, n_components_pca)\n",
    "\n",
    "    # 3. Dividere il train set in set etichettato e non etichettato\n",
    "    x_labeled, y_labeled, x_unlabeled, y_unlabeled = create_semi_supervised_split(x_train_pca, y_train, labeled_fraction)\n",
    "\n",
    "    # 4. Calcolare le pseudo-labels\n",
    "    pseudo_labels = get_pseudo_labels(x_unlabeled, x_labeled, y_labeled, n_clusters)\n",
    "\n",
    "    # 5. Calcolare l'accuracy delle pseudo-labels\n",
    "    pseudo_labels_accuracy = accuracy_score(y_unlabeled, pseudo_labels[~np.isnan(pseudo_labels)])\n",
    "    print(f\"Accuracy delle pseudo-labels: {pseudo_labels_accuracy:.4f}\")\n",
    "\n",
    "    # 6. Allenare e valutare il modello solo sui dati etichettati (L)\n",
    "    train_and_evaluate_classifier(\n",
    "        classifier_class,\n",
    "        classifier_args,\n",
    "        x_labeled,\n",
    "        y_labeled,\n",
    "        x_test_pca,\n",
    "        y_test,\n",
    "        \"Modello allenato solo sui dati etichettati (L)\",\n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    # 7. Allenare e valutare il modello solo sui dati non etichettati (U)\n",
    "    train_and_evaluate_classifier(\n",
    "        classifier_class,\n",
    "        classifier_args,\n",
    "        x_unlabeled,\n",
    "        pseudo_labels,\n",
    "        x_test_pca,\n",
    "        y_test,\n",
    "        \"Modello allenato solo sui dati non etichettati (U)\",\n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    # 8. Allenare e valutare il modello sui dati etichettati (L) più quelli non etichettati (U)\n",
    "    x_combined = np.vstack((x_labeled, x_unlabeled))\n",
    "    y_combined = np.hstack((y_labeled, pseudo_labels))\n",
    "    train_and_evaluate_classifier(\n",
    "        classifier_class,\n",
    "        classifier_args,\n",
    "        x_combined,\n",
    "        y_combined,\n",
    "        x_test_pca,\n",
    "        y_test,\n",
    "        \"Modello allenato sui dati etichettati (L) + non etichettati (U)\",\n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    # 9. Allenare e valutare il modello su tutto il dataset originale\n",
    "    train_and_evaluate_classifier(\n",
    "        classifier_class,\n",
    "        classifier_args,\n",
    "        x_train_pca,\n",
    "        y_train,\n",
    "        x_test_pca,\n",
    "        y_test,\n",
    "        \"Modello allenato su tutto il dataset originale\",\n",
    "        class_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4e39c",
   "metadata": {},
   "source": [
    "### **Utilizzare la funzione `main`**\n",
    "\n",
    "Specifichiamo adesso un set di parametri richiesti dalla funzione main e utilizziamola. Nello specifico la funzione main ha bisogno di:\n",
    "\n",
    "* `classifier_class`: quale classificatore utilizzare, ad esempio `'MLPClassifier'`, `'LogisticRegression'` o altri visti in precedenza.\n",
    "* `classifier_args`: un dizionario contenente i parametri del classificatore scelto, ad esempio un `MLPClassifier` necessiterà del parametro `hidden_layer_sizes`. Dipendentemente da quale classificatore scegliete dovrete creare il dizionario.\n",
    "* `n_components_pca`: numero di componenti di PCA che vogliamo utilizzare. Se specifichiamo un valore compreso in [0, 1] questo verrà considerato come la percentuale di varianza che vogliamo mentenere.\n",
    "* `labeled_fraction`: percentuale di dati da usare come insieme etichettato. Si consiglia il valore 0.002 corrispondente allo 0.2%, cioè 16 immagini su 8000.\n",
    "* `n_clusters`: numero di cluster da utilizzare, nel nostro caso vogliamo che ci sia un cluster per ogni classe, quindi 10.\n",
    "\n",
    "Infine utilizziamo la funzione main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "beadf602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri\n",
    "CLASSIFIER_CLASS = MLPClassifier  # Modello da usare, ad esempio LogisticRegression o SVC\n",
    "CLASSIFIER_ARGS = {\n",
    "    'max_iter': 20,\n",
    "    'hidden_layer_sizes': (200,200)  # Aumenta il numero di iterazioni per la convergenza\n",
    "}\n",
    "N_COMPONENTS_PCA = 0.95  # Mantiene il 95% della varianza spiegata, o un numero fisso es. 50\n",
    "LABELED_FRACTION = 0.002   # Frazione di dati da usare come insieme etichettato L\n",
    "N_CLUSTERS = 10          # Fashion-MNIST ha 10 classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9d2cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni training set: (8000, 784), (8000,)\n",
      "Dimensioni test set: (1000, 784), (1000,)\n",
      "PCA applicata. Numero di componenti selezionate: 241\n",
      "Varianza totale spiegata: 0.9503\n",
      "Dimensione insieme etichettato (L): 16\n",
      "Dimensione insieme non etichettato (U): 7984\n",
      "Attenzione: Cluster 2 non ha campioni etichettati per il mapping. Assegno NaN.\n",
      "Attenzione: Cluster 7 non ha campioni etichettati per il mapping. Assegno NaN.\n",
      "Attenzione: Cluster 8 non ha campioni etichettati per il mapping. Assegno NaN.\n",
      "(7984,)\n",
      "\n",
      "Accuratezza delle pseudo-etichette (sui campioni mappabili di U): 0.5052\n",
      "Baseline - Solo dati etichettati (L)\n",
      "Accuratezza su test set: 0.4040\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.50      0.09      0.16       107\n",
      "     Trouser       0.77      0.81      0.79       105\n",
      "    Pullover       0.24      0.75      0.36       111\n",
      "       Dress       0.89      0.18      0.30        93\n",
      "        Coat       0.29      0.30      0.29       115\n",
      "      Sandal       0.39      0.54      0.46        87\n",
      "       Shirt       0.33      0.49      0.40        97\n",
      "     Sneaker       0.63      0.25      0.36        95\n",
      "         Bag       0.60      0.28      0.39        95\n",
      "  Ankle boot       0.81      0.31      0.44        95\n",
      "\n",
      "    accuracy                           0.40      1000\n",
      "   macro avg       0.54      0.40      0.39      1000\n",
      "weighted avg       0.54      0.40      0.39      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amasano/miniconda3/envs/pytorchenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/amasano/miniconda3/envs/pytorchenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solo dati con pseudo-etichette (U_pseudo)\n",
      "Accuratezza su test set: 0.4740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.00      0.00      0.00       107\n",
      "     Trouser       0.63      0.90      0.74       105\n",
      "    Pullover       0.30      0.54      0.39       111\n",
      "       Dress       0.00      0.00      0.00        93\n",
      "        Coat       0.27      0.59      0.37       115\n",
      "      Sandal       0.50      0.66      0.56        87\n",
      "       Shirt       0.00      0.00      0.00        97\n",
      "     Sneaker       0.56      0.85      0.68        95\n",
      "         Bag       0.97      0.41      0.58        95\n",
      "  Ankle boot       0.78      0.78      0.78        95\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.40      0.47      0.41      1000\n",
      "weighted avg       0.39      0.47      0.41      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amasano/miniconda3/envs/pytorchenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinato - Dati etichettati (L) + Pseudo-etichette (U_pseudo)\n",
      "Accuratezza su test set: 0.4670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.00      0.00      0.00       107\n",
      "     Trouser       0.63      0.90      0.74       105\n",
      "    Pullover       0.28      0.54      0.37       111\n",
      "       Dress       0.00      0.00      0.00        93\n",
      "        Coat       0.26      0.57      0.36       115\n",
      "      Sandal       0.52      0.66      0.58        87\n",
      "       Shirt       0.00      0.00      0.00        97\n",
      "     Sneaker       0.56      0.85      0.68        95\n",
      "         Bag       0.97      0.37      0.53        95\n",
      "  Ankle boot       0.77      0.78      0.77        95\n",
      "\n",
      "    accuracy                           0.47      1000\n",
      "   macro avg       0.40      0.47      0.40      1000\n",
      "weighted avg       0.39      0.47      0.40      1000\n",
      "\n",
      "Oracle - Supervisione completa (intero training set)\n",
      "Accuratezza su test set: 0.8480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.79      0.82      0.80       107\n",
      "     Trouser       0.98      0.95      0.97       105\n",
      "    Pullover       0.74      0.78      0.76       111\n",
      "       Dress       0.82      0.83      0.82        93\n",
      "        Coat       0.80      0.75      0.77       115\n",
      "      Sandal       0.96      0.93      0.95        87\n",
      "       Shirt       0.64      0.63      0.63        97\n",
      "     Sneaker       0.90      0.96      0.93        95\n",
      "         Bag       0.95      0.95      0.95        95\n",
      "  Ankle boot       0.96      0.92      0.94        95\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.85      0.85      0.85      1000\n",
      "weighted avg       0.85      0.85      0.85      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amasano/miniconda3/envs/pytorchenv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "main(\n",
    "    CLASSIFIER_CLASS,\n",
    "    CLASSIFIER_ARGS,\n",
    "    N_COMPONENTS_PCA,\n",
    "    LABELED_FRACTION,\n",
    "    N_CLUSTERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d4e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
